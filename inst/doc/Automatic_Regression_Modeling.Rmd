---
title: "Automatic Regression Modeling"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Automatic Regression Modeling}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = NA
)
```

## Installation

You can install autoReg package on github. 

```{r, eval=FALSE}
#install.packages("devtools")
devtools::install_github("cardiomoon/autoReg")
```

## Load package

To load the package, use library() function.
```{r}
library(autoReg)
library(dplyr)
```

## Linear model with multiple variables

The package `autoReg` aims automatic selection of explanatory variables of regression models. Let's begin with famous mtcars data. We select mpg(miles per gallon) as a dependent variable and select wt(weight), hp(horse power) and am(transmission, 0=automatic, 1=manual) as explanatory variables and included all possible interaction. The autoReg() function make a table summarizing the result of analysis.


```{r}
fit=lm(mpg~wt*hp*am,data=mtcars)
autoReg(fit) 
```

You can make a publication-ready table easily using myft(). It makes a flextable object which can use in HTML, PDF, microsoft word or powerpoint file.

```{r}
autoReg(fit) %>% myft()
```

From the result of multivariable analysis, we found no explanatory variable is significant.

### Selection of explanatory variable from univariable model

You can start with univariable model. With a list of univariable model, you can select potentially significant explanatory variable(p value below 0.2 for example). The autoReg() function automatically select from univariable model with a given p value threshold(default value is 0.2).

```{r}
autoReg(fit,uni=TRUE, threshold=0.2) %>% myft()
```
As you can see in the above table, the coefficients of hp:am(the interaction of hp and am) and wt:hp:am (interaction of wt and hp and am) have p-values above 0.2. So these variables are excluded and the remaining variables are used in multivariable model. If you want to use all the explanatory variables in the multivariable model, set the threshold 1.

### Stepwise backward elimination  

From the multivariable model, you can perform stepwise backward elimination with step() function.

```{r}
fit=lm(mpg~hp+wt+am+wt:hp+wt:am,data=mtcars)
final=step(fit,trace=0)
summary(final)
```
You can perform univariable analysis for variable selection, multivariable analysis and stepwise backward elimination in one step.

```{r}
fit=lm(mpg~hp*wt*am,data=mtcars)
autoReg(fit,uni=TRUE,final=TRUE) %>% myft()
```

## Linear model with interaction between categorical variable

You can use autoReg() function for models with interaction with categorical variable(s).

```{r}
fit=lm(Sepal.Length~Sepal.Width*Species,data=iris)
autoReg(fit,uni=TRUE, final=TRUE) %>% myft()
```

## Missing data - automatic multiple imputation

### Original data

Let us think about linear regression model with iris data. In this model, Sepal.Length 
is the dependent variable and Sepal.Width and Species are explanatory variables. You can 
make a table summarizing the result as follows.

```{r}
df=gaze(Sepal.Length~Sepal.Width+Species,data=iris)
df %>% myft()
```

```{r}
fit=lm(Sepal.Length~Sepal.Width+Species,data=iris)
df=addFitSummary(df,fit,"Coefficient (original data)")
df %>% myft()
```

### Missed data

For simulation of the MCAR(missing at completely random) data, one third of the 
Sepal.Width records are replace with NA(missing). If you want to perform missing data analysis,
use gaze() function with missing=TRUE.


```{r}
iris1=iris
set.seed=123
no=sample(1:150,50,replace=FALSE)
iris1$Sepal.Width[no]=NA
gaze(Sepal.Width~.,data=iris1,missing=TRUE) %>% myft()
```

And then we do same analysis  with this data.

```{r}
fit1=lm(Sepal.Length~Sepal.Width+Species,data=iris1)
df=addFitSummary(df,fit1,"Coefficient (missed data)")
df %>% myft()
```
### Multiple imputation

You can do multiple imputation by using imputedReg() function. This function perform 
multiple imputation using mice() function in mice package. The default value of the number of multiple imputation
is 20. You can adjust the number with m argument. You can set random number generator with seed argument.

```{r}
fit2=imputedReg(fit1, m=20,seed=1234)
df=addFitSummary(df,fit2,statsname="Coefficient (imputed)")
df %>% myft()
```

You can make a plot summarizing models with modelPlot() function.

```{r,fig.width=8,fig.height=5}
modelPlot(fit1,imputed=TRUE)
```

